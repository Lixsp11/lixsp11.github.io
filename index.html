<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhen Li</title>

  <meta name="author" content="Zhen Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <style>
    .modal-overlay {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.3);
      z-index: 1000;
      justify-content: center;
      align-items: center;
    }

    .modal {
      background: #fff;
      padding: 24px 32px;
      border-radius: 10px;
      box-shadow: 0 2px 16px rgba(0, 0, 0, 0.2);
      text-align: center;
      min-width: 260px;
      position: relative;
    }

    .modal-close {
      position: absolute;
      top: 8px;
      right: 12px;
      background: none;
      border: none;
      font-size: 20px;
      cursor: pointer;
      color: #888;
    }
  </style>

</head>

<body>
  <div class="modal-overlay" id="modal-overlay">
    <div class="modal">
      <button class="modal-close" id="modal-close" title="Close">√ó</button>
      <div>EmailÔºöli.zhen [AT] bit.edu.cn</div>
    </div>
  </div>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Zhen Li „ÄåÊùé Á•Ø„Äç
                  </p>
                  <p>
                    I am a final-year master's student at Beijing Institute of Technology, supervised by <a
                      href="https://wu-yuwei-bit.github.io/">Prof. Yuwei Wu</a> and <a
                      href="https://scholar.google.com/citations?user=Sl6TV7gAAAAJ">Prof. Yunde Jia</a>.
                    I am currently interning at the Shanda AI Research, working closely with <a
                      href="https://kpzhang93.github.io/">Dr. Kaipeng Zhang</a> and <a
                      href="http://www.bozheng-lab.com/">Dr. Bo Zheng</a>.
                    Prior to that, I obtained my Bachelor's degree from the <a
                      href="https://xuteli.bit.edu.cn/english/ABOUTSX/Introductionsx/index.htm">Xuteli School</a> at
                    Beijing Institute of Technology in 2023.
                    <br><br>
                    My research interests lie at (1) the intersection of vision-and-language and compositional
                    generalization, (2) video generation incorporating 3D priors.
                  </p>
                  <p style="text-align:center">
                    <a href="#" id="email-link">Email</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com.hk/citations?user=aKvi_rEAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/Lixsp11/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:37%;max-width:37%">
                  <a href="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/ZhenLi.png"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/ZhenLi.png"
                      class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:4px;width:100%;vertical-align:middle">
                  <h2>Selected Publications</h2>
                  <p>
                    * indicates equal contribution. <sup style="font-size: 0.7em;">üìß</sup> indicates corresponding
                    author.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:1.2%;width:30%;max-width:30%" align="center">
                  <img style="width:100%"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/omnicustom-banner.png">
                </td>
                <td width="70%" valign="center">
                  <a href="https://arxiv.org/abs/2602.12304">
                    <span class="papertitle">OmniCustom: Sync Audio-Video Customization Via Joint Audio-Video
                      Generation Model</span>
                  </a>
                  <br>
                  Maomao Li, <strong>Zhen Li</strong>, Kaipeng Zhang, Guosheng Yin, Zhifeng Li, Dong Xu
                  <br>
                  <em>Arxiv</em>, 2026.02
                  <br>
                  [<a href="https://arxiv.org/abs/2602.12304">Paper</a>]
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:1.2%;width:30%;max-width:30%" align="center">
                  <img style="width:100%"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/yume1_5-banner.png">
                </td>
                <td width="70%" valign="center">
                  <a href="https://arxiv.org/abs/2512.22096">
                    <span class="papertitle">Yume1.5: A Text-Controlled Interactive World Generation Model</span>
                  </a>
                  <br>
                  Xiaofeng Mao, <strong>Zhen Li</strong>, Chuanhao Li, Xiaojie Xu, Kaining Ying, Tong He, 
                  Jiangmiao Pang, Yu Qiao, Kaipeng Zhang<sup style="font-size: 0.7em;">üìß</sup>
                  <br>
                  <em>Arxiv</em>, 2025.12
                  <br>
                  [<a href="https://stdstu12.github.io/YUME-Project">Project Page</a>]&nbsp;/&nbsp;
                  [<a href="https://arxiv.org/abs/2512.22096">Paper</a>]&nbsp;/&nbsp;
                  [<a href="https://github.com/stdstu12/YUME">Code</a>]
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:1.2%;width:30%;max-width:30%" align="center">
                  <img style="width:100%"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/compil-banner.png">
                </td>
                <td width="70%" valign="center">
                  <a href="https://arxiv.org/abs/2511.09082">
                    <span class="papertitle">Composition-Incremental Learning for Compositional Generalization</span>
                  </a>
                  <br>
                  <strong>Zhen Li</strong>, Yuwei Wu, Chenchen Jing, Che Sun<sup style="font-size: 0.7em;">üìß</sup>,
                  Chuanhao Li<sup style="font-size: 0.7em;">üìß</sup>, Yunde Jia
                  <br>
                  <em>AAAI</em>, 2026
                  <br>
                  [<a href="https://arxiv.org/abs/2511.09082">Paper</a>]&nbsp;/&nbsp;
                  [<a href="https://github.com/Lixsp11/CompIL">Code</a>]
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:1.2%;width:30%;max-width:30%" align="center">
                  <img style="width:100%"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/sekai-banner.png">
                </td>
                <td width="70%" valign="center">
                  <a href="https://arxiv.org/abs/2506.15675">
                    <span class="papertitle">Sekai: A Video Dataset towards World Exploration</span>
                  </a>
                  <br>
                  <strong>Zhen Li</strong>, Chuanhao Li<sup style="font-size: 0.7em;">üìß</sup>, Xiaofeng Mao, Shaoheng
                  Lin, Ming Li, Shitian Zhao,
                  Zhaopan Xu, Xinyue Li, Yukang Feng, Jianwen Sun, Zizhen Li, Fanrui Zhang, Jiaxin Ai, Zhixiang Wang,
                  Yuwei Wu<sup style="font-size: 0.7em;">üìß</sup>, Tong He, Jiangmiao Pang, Yu Qiao, Yunde Jia, Kaipeng
                  Zhang<sup style="font-size: 0.7em;">üìß</sup>
                  <br>
                  <em>NeurIPS</em>, 2025
                  <br>
                  [<a href="https://lixsp11.github.io/sekai-project/">Project Page</a>]&nbsp;/&nbsp;
                  [<a href="https://arxiv.org/abs/2506.15675">Paper</a>]&nbsp;/&nbsp;
                  [<a href="https://github.com/Lixsp11/sekai-codebase">Code</a>]
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:1.2%;width:30%;max-width:30%" align="center">
                  <img style="width:100%"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/aaai2025-banner.png">
                </td>
                <td width="70%" valign="center">
                  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/32492">
                    <span class="papertitle">Consistency of Compositional Generalization Across Multiple Levels</span>
                  </a>
                  <br>
                  Chuanhao Li*, <strong>Zhen Li*</strong>, Chenchen Jing<sup style="font-size: 0.7em;">üìß</sup>,
                  Xiaomeng Fan, Wenbo Ye, Yuwei Wu<sup style="font-size: 0.7em;">üìß</sup>, Yunde Jia
                  <br>
                  <em>AAAI</em>, 2025
                  <br>
                  [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/32492">Paper</a>]&nbsp;/&nbsp;
                  [<a href="https://github.com/NeverMoreLCH/CCG">Code</a>]
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:1.2%;width:30%;max-width:30%" align="center">
                  <img style="width:100%"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/ijcai2025-banner.png">
                </td>
                <td width="70%" valign="center">
                  <a href="https://arxiv.org/abs/2505.23045">
                    <span class="papertitle">Multi-Sourced Compositional Generalization in Visual Question
                      Answering</span>
                  </a>
                  <br>
                  Chuanhao Li*, Wenbo Ye*, <strong>Zhen Li</strong>, Yuwei Wu<sup style="font-size: 0.7em;">üìß</sup>,
                  Yunde Jia
                  <br>
                  <em>IJCAI</em>, 2025
                  <br>
                  [<a href="https://arxiv.org/abs/2505.23045">Paper</a>]&nbsp;/&nbsp;
                  [<a href="https://github.com/NeverMoreLCH/MSCG">Code</a>]
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:1.2%;width:30%;max-width:30%" align="center">
                  <img style="width:100%"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/eccv2024-banner.png">
                </td>
                <td width="70%" valign="center">
                  <a href="https://link.springer.com/chapter/10.1007/978-3-031-73195-2_9">
                    <span class="papertitle">Compositional Substitutivity of Visual Reasoning for Visual Question
                      Answering</span>
                  </a>
                  <br>
                  Chuanhao Li*, <strong>Zhen Li*</strong>, Chenchen Jing<sup style="font-size: 0.7em;">üìß</sup>, Yuwei
                  Wu<sup style="font-size: 0.7em;">üìß</sup>, Mingliang Zhai, Yunde Jia
                  <br>
                  <em>ECCV</em>, 2024
                  <br>
                  [<a href="https://link.springer.com/chapter/10.1007/978-3-031-73195-2_9">Paper</a>]&nbsp;/&nbsp;
                  [<a href="https://github.com/NeverMoreLCH/CG-SPS">Code</a>]
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:1.2%;width:30%;max-width:30%" align="center">
                  <img style="width:100%"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/neurips2024-banner.png">
                </td>
                <td width="70%" valign="center">
                  <a href="https://arxiv.org/abs/2405.14554">
                    <span class="papertitle">SearchLVLMs: A Plug-and-Play Framework for Augmenting Large Vision-Language
                      Models by Searching Up-to-Date Internet Knowledge</span>
                  </a>
                  <br>
                  Chuanhao Li, <strong>Zhen Li</strong>, Chenchen Jing, Shuo Liu, Wenqi Shao, Yuwei Wu<sup
                    style="font-size: 0.7em;">üìß</sup>, Ping Luo, Yu Qiao, Kaipeng Zhang<sup
                    style="font-size: 0.7em;">üìß</sup>
                  <br>
                  <em>NeurIPS</em>, 2024
                  <br>
                  [<a href="https://nevermorelch.github.io/SearchLVLMs.github.io/">Project Page</a>]&nbsp;/&nbsp;
                  [<a href="https://arxiv.org/abs/2405.14554">Paper</a>]&nbsp;/&nbsp;
                  [<a href="https://github.com/NeverMoreLCH/SearchLVLMs">Code</a>]
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:1.2%;width:30%;max-width:30%" align="center">
                  <img style="width:100%"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/emnlp2024-banner.png">
                </td>
                <td width="70%" valign="center">
                  <a href="https://aclanthology.org/2024.emnlp-main.996/">
                    <span class="papertitle">In-Context Compositional Generalization for Large Vision-Language
                      Models</span>
                  </a>
                  <br>
                  Chuanhao Li, Chenchen Jing, <strong>Zhen Li</strong>, Mingliang Zhai, Yuwei Wu<sup
                    style="font-size: 0.7em;">üìß</sup>, Yunde Jia
                  <br>
                  <em>EMNLP</em>, 2024
                  <br>
                  [<a href="https://aclanthology.org/2024.emnlp-main.996/">Paper</a>]
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:1.2%;width:30%;max-width:30%" align="center">
                  <img style="width:100%"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/cvpr2023-banner.png">
                </td>
                <td width="70%" valign="center">
                  <a
                    href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Exploring_the_Effect_of_Primitives_for_Compositional_Generalization_in_Vision-and-Language_CVPR_2023_paper.html">
                    <span class="papertitle">Exploring the Effect of Primitives for Compositional Generalization in
                      Vision-and-Language</span>
                  </a>
                  <br>
                  Chuanhao Li, <strong>Zhen Li</strong>, Chenchen Jing<sup style="font-size: 0.7em;">üìß</sup>, Yuwei
                  Wu<sup style="font-size: 0.7em;">üìß</sup>, Yunde Jia
                  <br>
                  <em>CVPR</em>, 2023
                  <br>
                  [<a
                    href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Exploring_the_Effect_of_Primitives_for_Compositional_Generalization_in_Vision-and-Language_CVPR_2023_paper.html">Paper</a>]&nbsp;/&nbsp;
                  [<a href="https://github.com/NeverMoreLCH/SSL2CG">Code</a>]
                  <br>
                </td>
              </tr>

            </tbody>
          </table>
        </td>
      </tr>
    </tbody>
  </table>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:14px;width:100%;vertical-align:middle">
                  <h2>Experiences</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="width:30%;" align="center">
                  <img style="width:50%;"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/shanda.png"
                    alt="shanghai_ai">
                </td>
                <td width="70%" valign="top">
                  <p>
                    <strong> Jan. 2026 - Present</strong>,
                  </p>
                  <p>
                    Research Intern, Shanda AI Research.
                  </p>
                  <p>Mentor: <a href="https://kpzhang93.github.io/">Kaipeng Zhang</a></p>
                </td>
              </tr>

              <tr>
                <td style="width:30%;" align="center">
                  <img style="width:50%;"
                    src="https://cdn.jsdelivr.net/gh/Lixsp11/lixsp11.github.io@0.4.0/images/shanghai_ai_lab.png"
                    alt="shanghai_ai">
                </td>
                <td width="70%" valign="top">
                  <p>
                    <strong> Feb. 2025 - Dec. 2025</strong>,
                  </p>
                  <p>
                    Research Intern, Shanghai Artificial Intellience Laboratory.
                  </p>
                  <p>Mentor: <a href="https://kpzhang93.github.io/">Kaipeng Zhang</a></p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
    </tbody>
  </table>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px;">
        <td style="padding:0px; text-align:center;">
          <div style="max-width:100px; margin:0 auto; display:block;">
            <script type="text/javascript" id="clstr_globe"
              src="//clustrmaps.com/globe.js?d=R5Mc7ZCXGyC-S7CIviKHLdOgfjB-L-G1pNl5laCQUhk"></script>
          </div>
        </td>
      </tr>
      <tr style="padding:0px;">
        <td style="padding:0px; text-align:center;">
          <p>Copyright ¬© Zhen Li 2020 | Last updated: Feb. 17, 2026 |
            Template from <a href="https://jonbarron.info/">Jon Barron</a>
          </p>
        </td>
      </tr>
    </tbody>
  </table>
</body>

<script>
  document.getElementById('email-link').onclick = function (e) {
    e.preventDefault();
    document.getElementById('modal-overlay').style.display = 'flex';
  };
  document.getElementById('modal-close').onclick = function () {
    document.getElementById('modal-overlay').style.display = 'none';
  };
  document.getElementById('modal-overlay').onclick = function (e) {
    if (e.target === this) {
      this.style.display = 'none';
    }
  };
</script>

</html>
